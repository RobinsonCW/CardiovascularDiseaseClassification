{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Three - Clustering\n",
    "\n",
    "\n",
    "Team Members\n",
    "* Chance Robinson\n",
    "* Dan Crouthamel\n",
    "* Shane Weinstock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding 1\n",
    "\n",
    "\n",
    "_Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). How will you measure the effectiveness of a good algorithm? Why does your chosen validation method make sense for this specific dataset and the stakeholders needs?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Imports\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "# Pre-Processing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Metrics and Evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "# Train/ Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Imbalanced Data\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.over_sampling import BorderlineSMOTE\n",
    "# from imblearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "# Estimators\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Hyper Parameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# T-Tests\n",
    "# from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "# Machine Learning Visualizations\n",
    "# from yellowbrick.classifier import ROCAUC\n",
    "# from yellowbrick.classifier import PrecisionRecallCurve\n",
    "# from yellowbrick.classifier import ClassificationReport\n",
    "\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding 1\n",
    "\n",
    "_Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file. Verify data quality: Are there missing values? Duplicate data? Outliers? Are those mistakes? How do you deal with these problems?_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../../../../data/cardio_train.csv', delimiter=';')\n",
    "# set id as index\n",
    "df.set_index(\"id\", inplace=True)\n",
    "# copy original data\n",
    "df_clean = df.copy(deep=True)\n",
    "# drop duplicates\n",
    "df_clean.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# re-encode gender to male (1) and female (0)\n",
    "df_clean['gender'] = np.where((df_clean.gender == 2), 1, 0)\n",
    "# If > 200, replace with ap_hi median (120)\n",
    "# If < 80 (median for ap_lo), replace with ap_hi median (120)\n",
    "df_clean['ap_hi'] = np.where(df_clean['ap_hi'] > 200, 120, df_clean['ap_hi'])\n",
    "df_clean['ap_hi'] = np.where(df_clean['ap_hi'] < 80, 120, df_clean['ap_hi'])\n",
    "# If > 120 (median for hi), replace with ap_lo median (80)\n",
    "# If < 0 replace with ap_lo median (80)\n",
    "df_clean['ap_lo'] = np.where(df_clean['ap_lo'] > 120, 80, df_clean['ap_lo'])\n",
    "df_clean['ap_lo'] = np.where(df_clean['ap_lo'] < 0, 80, df_clean['ap_lo'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 1: Cardiovascular Dataset - Attribute Descriptions**\n",
    "\n",
    "| Column Description | Feature Type | Column Name | Data Type |\n",
    "|:---|:---|:---|:---|\n",
    "| **Age**                        | Objective | age | int (days) |\n",
    "| **Height**                     | Objective | height | int (cm) |\n",
    "| **Weight**                     | Objective | weight | float (kg) |\n",
    "| **Gender**                     | Objective | gender | 0: female, 1: male |\n",
    "| **Systolic blood pressure**    | Examination | ap_hi | int |\n",
    "| **Diastolic blood pressure**   | Examination | ap_lo | int |\n",
    "| **Cholesterol**                | Examination | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n",
    "| **Glucose**                    | Examination | gluc | 1: normal, 2: above normal, 3: well above normal |\n",
    "| **Smoking**                    | Subjective  | smoke | binary |\n",
    "| **Alcohol intake**             | Subjective | alco | binary |\n",
    "| **Physical activity**          | Subjective | active | binary |\n",
    "| **Has CVD?**                   | Target * | cardio | binary |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                age        gender        height        weight         ap_hi  \\\ncount  69976.000000  69976.000000  69976.000000  69976.000000  69976.000000   \nmean   19468.950126      0.349648    164.359152     74.208519    126.911398   \nstd     2467.374620      0.476862      8.211218     14.397211     16.839718   \nmin    10798.000000      0.000000     55.000000     10.000000     80.000000   \n25%    17664.000000      0.000000    159.000000     65.000000    120.000000   \n50%    19703.000000      0.000000    165.000000     72.000000    120.000000   \n75%    21327.000000      1.000000    170.000000     82.000000    140.000000   \nmax    23713.000000      1.000000    250.000000    200.000000    200.000000   \n\n              ap_lo   cholesterol          gluc         smoke          alco  \\\ncount  69976.000000  69976.000000  69976.000000  69976.000000  69976.000000   \nmean      81.215145      1.366997      1.226535      0.088159      0.053790   \nstd        9.533994      0.680333      0.572353      0.283528      0.225604   \nmin        0.000000      1.000000      1.000000      0.000000      0.000000   \n25%       80.000000      1.000000      1.000000      0.000000      0.000000   \n50%       80.000000      1.000000      1.000000      0.000000      0.000000   \n75%       90.000000      2.000000      1.000000      0.000000      0.000000   \nmax      120.000000      3.000000      3.000000      1.000000      1.000000   \n\n             active        cardio  \ncount  69976.000000  69976.000000  \nmean       0.803718      0.499771  \nstd        0.397187      0.500004  \nmin        0.000000      0.000000  \n25%        1.000000      0.000000  \n50%        1.000000      0.000000  \n75%        1.000000      1.000000  \nmax        1.000000      1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>gender</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>ap_hi</th>\n      <th>ap_lo</th>\n      <th>cholesterol</th>\n      <th>gluc</th>\n      <th>smoke</th>\n      <th>alco</th>\n      <th>active</th>\n      <th>cardio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>19468.950126</td>\n      <td>0.349648</td>\n      <td>164.359152</td>\n      <td>74.208519</td>\n      <td>126.911398</td>\n      <td>81.215145</td>\n      <td>1.366997</td>\n      <td>1.226535</td>\n      <td>0.088159</td>\n      <td>0.053790</td>\n      <td>0.803718</td>\n      <td>0.499771</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2467.374620</td>\n      <td>0.476862</td>\n      <td>8.211218</td>\n      <td>14.397211</td>\n      <td>16.839718</td>\n      <td>9.533994</td>\n      <td>0.680333</td>\n      <td>0.572353</td>\n      <td>0.283528</td>\n      <td>0.225604</td>\n      <td>0.397187</td>\n      <td>0.500004</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>10798.000000</td>\n      <td>0.000000</td>\n      <td>55.000000</td>\n      <td>10.000000</td>\n      <td>80.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>17664.000000</td>\n      <td>0.000000</td>\n      <td>159.000000</td>\n      <td>65.000000</td>\n      <td>120.000000</td>\n      <td>80.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>19703.000000</td>\n      <td>0.000000</td>\n      <td>165.000000</td>\n      <td>72.000000</td>\n      <td>120.000000</td>\n      <td>80.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>21327.000000</td>\n      <td>1.000000</td>\n      <td>170.000000</td>\n      <td>82.000000</td>\n      <td>140.000000</td>\n      <td>90.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>23713.000000</td>\n      <td>1.000000</td>\n      <td>250.000000</td>\n      <td>200.000000</td>\n      <td>200.000000</td>\n      <td>120.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding 2\n",
    "\n",
    "\n",
    "_Visualize the any important attributes appropriately. Important: Provide an interpretation for any charts or graphs._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Classification Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Average ROC (AUC) =  79.1507617264313 +- 0.5833047553922216\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "numeric_features = ['age', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc']\n",
    "categorical_features = ['gender', 'smoke', 'alco', 'active']\n",
    "\n",
    "# Impute Numeric Features with the mean value\n",
    "\n",
    "# One Hot Encode Categorical Features\n",
    "\n",
    "# Robust Scaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "rs = RobustScaler()\n",
    "df_clean[[\"age\", \"height\", \"weight\", \"ap_hi\", \"ap_lo\"]] = rs.fit_transform(df_clean[[\"age\", \"height\", \"weight\", \"ap_hi\", \"ap_lo\"]])\n",
    "\n",
    "\n",
    "X_cols = ['age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "y = df_clean['cardio']\n",
    "X = df_clean[X_cols]\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "clf_logreg = LogisticRegression(random_state=1, penalty='l2', C=.01)\n",
    "\n",
    "\n",
    "roc = cross_val_score(clf_logreg, X, y=y, cv=cv, scoring='roc_auc')\n",
    "\n",
    "print (\"Average ROC (AUC) = \", roc.mean()*100, \"+-\", roc.std()*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 1\n",
    "\n",
    "\n",
    "_Train and adjust parameters_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Clustering\n",
    "\n",
    "- Creates partitional clusters that are center based and well separated\n",
    "- Associates each cluster with a centroid (center point)\n",
    "- Assigns each point to the cluster with the closest centroid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "number of estimated clusters : 154\nAverage ROC (AUC) =  78.94338909898822 +- 0.5381981228929272\nnumber of estimated clusters : 188\nAverage ROC (AUC) =  78.84830715592112 +- 0.5304186823245592\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3b330f0ce4fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeanShift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbandwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbandwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbin_seeding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mcluster_centers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\cluster\\_mean_shift.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m                 neighbor_idxs = nbrs.radius_neighbors([center],\n\u001b[1;32m--> 428\u001b[1;33m                                                       return_distance=False)[0]\n\u001b[0m\u001b[0;32m    429\u001b[0m                 \u001b[0munique\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneighbor_idxs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0munique\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# leave the current point as unique\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML7331\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mradius_neighbors\u001b[1;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[0;32m    970\u001b[0m                               sort_results=sort_results)\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    973\u001b[0m             )\n\u001b[0;32m    974\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML7331\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1025\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1027\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pickle_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML7331\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_terminate_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_terminate_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 734\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML7331\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# terminate does a join()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML7331\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML7331\\lib\\multiprocessing\\util.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[0;32m    187\u001b[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001b[0;32m    188\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[1;32m--> 189\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML7331\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36m_terminate_pool\u001b[1;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[0;32m    618\u001b[0m         \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'joining worker handler'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthreading\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mworker_handler\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[0mworker_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;31m# Terminate workers which haven't already finished.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML7331\\lib\\threading.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m             \u001b[1;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML7331\\lib\\threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# already determined that the C code is done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "quantiles = [0.05, 0.04, 0.03]\n",
    "\n",
    "for i in quantiles:\n",
    "    X2 = df_clean[['ap_hi','ap_lo']]\n",
    "\n",
    "    y = df_clean['cardio']\n",
    "    X = df_clean[['age', 'gender', 'height', 'weight', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']]\n",
    "\n",
    "    # The following bandwidth can be automatically detected using\n",
    "    bandwidth = estimate_bandwidth(X2, quantile=i, n_samples=500, n_jobs=-1, random_state=1)\n",
    "\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True, n_jobs=-1)\n",
    "    ms.fit(X2)\n",
    "    labels = ms.labels_\n",
    "    cluster_centers = ms.cluster_centers_\n",
    "\n",
    "    labels_unique = np.unique(labels)\n",
    "    n_clusters_ = len(labels_unique)\n",
    "\n",
    "    print(\"number of estimated clusters : %d\" % n_clusters_)\n",
    "\n",
    "\n",
    "    X = np.column_stack((X, pd.get_dummies(labels)))\n",
    "\n",
    "    roc = cross_val_score(clf_logreg, X, y=y, cv=cv, scoring='roc_auc')\n",
    "\n",
    "    print (\"Average ROC (AUC) = \", roc.mean()*100, \"+-\", roc.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 2\n",
    "\n",
    "\n",
    "_Evaluate and Compare_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 3\n",
    "\n",
    "\n",
    "_Visualize Results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 4\n",
    "\n",
    "_Summarize the Ramifications_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment \n",
    "\n",
    "\n",
    "_Be critical of your performance and tell the reader how you current model might be usable by other parties. Did you achieve your goals? If not, can you reign in the utility of your modeling? How useful is your model for interested parties (i.e., the companies or organizations that might want to use it)? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work\n",
    "\n",
    "\n",
    "_You have free reign to provide additional analyses or combine analyses._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = ['age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "y = df_clean['cardio']\n",
    "\n",
    "X = df_clean[X_cols]\n",
    "\n",
    "clf_logreg = LogisticRegression(random_state=1)\n",
    "\n",
    "pipe_logreg = Pipeline([['clf', clf_logreg]])\n",
    "\n",
    "model_params = {\n",
    "    # \"logisticregression\": {\n",
    "    #     \"model\": pipe_logreg,\n",
    "    #     \"params\": {\n",
    "    #         \"clf__C\": [.01, .1, 1, 5, 10, 25, 50],\n",
    "    #         \"clf__penalty\": [\"l1\", \"l2\"]\n",
    "    #     }\n",
    "    # }\n",
    "}\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    start = time.time()\n",
    "    # clf = GridSearchCV(estimator = mp[\"model\"], param_grid=mp[\"params\"], cv=10, scoring=\"roc_auc\", n_jobs=-1)\n",
    "    clf = RandomizedSearchCV(estimator = mp[\"model\"], param_distributions=mp[\"params\"], cv=10, scoring=\"roc_auc\", n_jobs=-1)\n",
    "    clf.fit(X, y)\n",
    "    elapsed_time = (time.time() - start)\n",
    "\n",
    "    scores.append({\"Model\": model_name,\n",
    "    \"Best ROC AUC\": clf.best_score_, # Mean cross-validated score of the best_estimator\n",
    "    \"Best Params\": clf.best_params_,\n",
    "    \"results\": clf.cv_results_,\n",
    "    \"Cross Validation Time\": elapsed_time,\n",
    "    \"Best Estimator\": clf.best_estimator_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10 Fold Cross Validation Scores (CVD):\n"
    }
   ],
   "source": [
    "print('10 Fold Cross Validation Scores (CVD):')\n",
    "\n",
    "for model in scores:\n",
    "    print()\n",
    "    for key, value in model.items():\n",
    "        if key == 'Best Estimator':\n",
    "            print(\"Prediction Accuracy\",': ',value.score(X, y))\n",
    "        elif key == 'results':\n",
    "            print('Mean Fit Time: ', value['mean_fit_time'].mean())\n",
    "            print('Mean Score Time: ', value['mean_score_time'].mean())\n",
    "        else:\n",
    "            print(key,': ',value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('ML7331': conda)",
   "language": "python",
   "name": "python_defaultSpec_1596746350743"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}