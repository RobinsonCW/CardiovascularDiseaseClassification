{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Three - Clustering\n",
    "\n",
    "\n",
    "Team Members\n",
    "* Chance Robinson\n",
    "* Dan Crouthamel\n",
    "* Shane Weinstock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding 1\n",
    "\n",
    "\n",
    "_Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). How will you measure the effectiveness of a good algorithm? Why does your chosen validation method make sense for this specific dataset and the stakeholders needs?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Imports\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Pre-Processing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Metrics and Evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "# Train/ Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Imbalanced Data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "# Estimators\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Hyper Parameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# T-Tests\n",
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "# Machine Learning Visualizations\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding 1\n",
    "\n",
    "_Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file. Verify data quality: Are there missing values? Duplicate data? Outliers? Are those mistakes? How do you deal with these problems?_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../../../../data/cardio_train.csv', delimiter=';')\n",
    "# set id as index\n",
    "df.set_index(\"id\", inplace=True)\n",
    "# copy original data\n",
    "df_clean = df.copy(deep=True)\n",
    "# drop duplicates\n",
    "df_clean.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 4)",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\Chance\\anaconda3\\envs\\ML7331\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3331\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-3-d769869c0400>\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    get_ipython().run_cell_magic('time', '', \"\\n# Convert age into years\\ndf_clean['age'] = (df_clean['age'] / 365).round().astype('int')\\n\\nre-encode gender to male (1) and female (0)\\ndf_clean['gender'] = np.where((df_clean.gender == 2), 1, 0)\\n\\n# compute the body mass index based on weight and height\\ndf_clean['bmi'] = df_clean['weight'] / (df_clean['height']/100)**2\\n\\n# create a BMI group\\ndf_clean['bmiGrp'] = np.where((df_clean.bmi < 18.5), 1, 0)\\ndf_clean['bmiGrp'] = np.where((df_clean.bmi >= 18.5) & (df_clean.bmi < 25), 2, df_clean.bmiGrp)\\ndf_clean['bmiGrp'] = np.where((df_clean.bmi >= 25) & (df_clean.bmi < 30), 3, df_clean.bmiGrp)\\ndf_clean['bmiGrp'] = np.where((df_clean.bmi >= 30), 4, df_clean.bmiGrp)\\n\\n# bin blood pressure groups based on the api hi/ lo variables\\ndf_clean['bp'] = np.where((df_clean.ap_hi < 120) & (df_clean.ap_lo < 80), 1, 0)\\ndf_clean['bp'] = np.where((df_clean.ap_hi >= 120) & (df_clean.ap_hi < 130) & (df_clean.ap_lo < 80), 2, df_clean.bp)\\ndf_clean['bp'] = np.where((df_clean.ap_hi >= 130) & (df_clean.ap_hi < 140) | ((df_clean.ap_lo >= 80) & (df_clean.ap_lo < 90)), 3, df_clean.bp)\\ndf_clean['bp'] = np.where((df_clean.ap_hi >= 140) | (df_clean.ap_lo >= 90), 4, df_clean.bp)\\ndf_clean['bp'] = np.where((df_clean.ap_hi > 180) | (df_clean.ap_lo > 120), 5, df_clean.bp)\\n\\n\")\n",
      "  File \u001b[0;32m\"C:\\Users\\Chance\\anaconda3\\envs\\ML7331\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m2362\u001b[0m, in \u001b[0;35mrun_cell_magic\u001b[0m\n    result = fn(*args, **kwargs)\n",
      "  File \u001b[0;32m\"<decorator-gen-62>\"\u001b[0m, line \u001b[0;32m2\u001b[0m, in \u001b[0;35mtime\u001b[0m\n",
      "  File \u001b[0;32m\"C:\\Users\\Chance\\anaconda3\\envs\\ML7331\\lib\\site-packages\\IPython\\core\\magic.py\"\u001b[0m, line \u001b[0;32m187\u001b[0m, in \u001b[0;35m<lambda>\u001b[0m\n    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \u001b[0;32m\"C:\\Users\\Chance\\anaconda3\\envs\\ML7331\\lib\\site-packages\\IPython\\core\\magics\\execution.py\"\u001b[0m, line \u001b[0;32m1268\u001b[0m, in \u001b[0;35mtime\u001b[0m\n    expr_ast = self.shell.compile.ast_parse(expr)\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Chance\\anaconda3\\envs\\ML7331\\lib\\site-packages\\IPython\\core\\compilerop.py\"\u001b[1;36m, line \u001b[1;32m101\u001b[1;36m, in \u001b[1;35mast_parse\u001b[1;36m\u001b[0m\n\u001b[1;33m    return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<unknown>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    re-encode gender to male (1) and female (0)\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Convert age into years\n",
    "df_clean['age'] = (df_clean['age'] / 365).round().astype('int')\n",
    "\n",
    "re-encode gender to male (1) and female (0)\n",
    "df_clean['gender'] = np.where((df_clean.gender == 2), 1, 0)\n",
    "\n",
    "# compute the body mass index based on weight and height\n",
    "df_clean['bmi'] = df_clean['weight'] / (df_clean['height']/100)**2\n",
    "\n",
    "# create a BMI group\n",
    "df_clean['bmiGrp'] = np.where((df_clean.bmi < 18.5), 1, 0)\n",
    "df_clean['bmiGrp'] = np.where((df_clean.bmi >= 18.5) & (df_clean.bmi < 25), 2, df_clean.bmiGrp)\n",
    "df_clean['bmiGrp'] = np.where((df_clean.bmi >= 25) & (df_clean.bmi < 30), 3, df_clean.bmiGrp)\n",
    "df_clean['bmiGrp'] = np.where((df_clean.bmi >= 30), 4, df_clean.bmiGrp)\n",
    "\n",
    "# bin blood pressure groups based on the api hi/ lo variables\n",
    "df_clean['bp'] = np.where((df_clean.ap_hi < 120) & (df_clean.ap_lo < 80), 1, 0)\n",
    "df_clean['bp'] = np.where((df_clean.ap_hi >= 120) & (df_clean.ap_hi < 130) & (df_clean.ap_lo < 80), 2, df_clean.bp)\n",
    "df_clean['bp'] = np.where((df_clean.ap_hi >= 130) & (df_clean.ap_hi < 140) | ((df_clean.ap_lo >= 80) & (df_clean.ap_lo < 90)), 3, df_clean.bp)\n",
    "df_clean['bp'] = np.where((df_clean.ap_hi >= 140) | (df_clean.ap_lo >= 90), 4, df_clean.bp)\n",
    "df_clean['bp'] = np.where((df_clean.ap_hi > 180) | (df_clean.ap_lo > 120), 5, df_clean.bp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table 1: Cardiovascular Dataset - Attribute Descriptions**\n",
    "\n",
    "| Column Description | Feature Type | Column Name | Data Type |\n",
    "|:---|:---|:---|:---|\n",
    "| **Age**                        | Objective | age | int (days) |\n",
    "| **Height**                     | Objective | height | int (cm) |\n",
    "| **Weight**                     | Objective | weight | float (kg) |\n",
    "| **Gender**                     | Objective | gender | 0: female, 1: male |\n",
    "| **Systolic blood pressure**    | Examination | ap_hi | int |\n",
    "| **Diastolic blood pressure**   | Examination | ap_lo | int |\n",
    "| **Cholesterol**                | Examination | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n",
    "| **Glucose**                    | Examination | gluc | 1: normal, 2: above normal, 3: well above normal |\n",
    "| **Smoking**                    | Subjective  | smoke | binary |\n",
    "| **Alcohol intake**             | Subjective | alco | binary |\n",
    "| **Physical activity**          | Subjective | active | binary |\n",
    "| **Has CVD?**                   | Target * | cardio | binary |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                age        gender        height        weight         ap_hi  \\\ncount  69976.000000  69976.000000  69976.000000  69976.000000  69976.000000   \nmean   19468.950126      1.349648    164.359152     74.208519    128.820453   \nstd     2467.374620      0.476862      8.211218     14.397211    154.037729   \nmin    10798.000000      1.000000     55.000000     10.000000   -150.000000   \n25%    17664.000000      1.000000    159.000000     65.000000    120.000000   \n50%    19703.000000      1.000000    165.000000     72.000000    120.000000   \n75%    21327.000000      2.000000    170.000000     82.000000    140.000000   \nmax    23713.000000      2.000000    250.000000    200.000000  16020.000000   \n\n              ap_lo   cholesterol          gluc         smoke          alco  \\\ncount  69976.000000  69976.000000  69976.000000  69976.000000  69976.000000   \nmean      96.636261      1.366997      1.226535      0.088159      0.053790   \nstd      188.504581      0.680333      0.572353      0.283528      0.225604   \nmin      -70.000000      1.000000      1.000000      0.000000      0.000000   \n25%       80.000000      1.000000      1.000000      0.000000      0.000000   \n50%       80.000000      1.000000      1.000000      0.000000      0.000000   \n75%       90.000000      2.000000      1.000000      0.000000      0.000000   \nmax    11000.000000      3.000000      3.000000      1.000000      1.000000   \n\n             active        cardio  \ncount  69976.000000  69976.000000  \nmean       0.803718      0.499771  \nstd        0.397187      0.500004  \nmin        0.000000      0.000000  \n25%        1.000000      0.000000  \n50%        1.000000      0.000000  \n75%        1.000000      1.000000  \nmax        1.000000      1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>gender</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>ap_hi</th>\n      <th>ap_lo</th>\n      <th>cholesterol</th>\n      <th>gluc</th>\n      <th>smoke</th>\n      <th>alco</th>\n      <th>active</th>\n      <th>cardio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n      <td>69976.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>19468.950126</td>\n      <td>1.349648</td>\n      <td>164.359152</td>\n      <td>74.208519</td>\n      <td>128.820453</td>\n      <td>96.636261</td>\n      <td>1.366997</td>\n      <td>1.226535</td>\n      <td>0.088159</td>\n      <td>0.053790</td>\n      <td>0.803718</td>\n      <td>0.499771</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2467.374620</td>\n      <td>0.476862</td>\n      <td>8.211218</td>\n      <td>14.397211</td>\n      <td>154.037729</td>\n      <td>188.504581</td>\n      <td>0.680333</td>\n      <td>0.572353</td>\n      <td>0.283528</td>\n      <td>0.225604</td>\n      <td>0.397187</td>\n      <td>0.500004</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>10798.000000</td>\n      <td>1.000000</td>\n      <td>55.000000</td>\n      <td>10.000000</td>\n      <td>-150.000000</td>\n      <td>-70.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>17664.000000</td>\n      <td>1.000000</td>\n      <td>159.000000</td>\n      <td>65.000000</td>\n      <td>120.000000</td>\n      <td>80.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>19703.000000</td>\n      <td>1.000000</td>\n      <td>165.000000</td>\n      <td>72.000000</td>\n      <td>120.000000</td>\n      <td>80.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>21327.000000</td>\n      <td>2.000000</td>\n      <td>170.000000</td>\n      <td>82.000000</td>\n      <td>140.000000</td>\n      <td>90.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>23713.000000</td>\n      <td>2.000000</td>\n      <td>250.000000</td>\n      <td>200.000000</td>\n      <td>16020.000000</td>\n      <td>11000.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Classification Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Average accuracy =  72.13616863439168 +- 0.5044950766893165\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "numeric_features = ['age', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc']\n",
    "categorical_features = ['gender', 'smoke', 'alco', 'active']\n",
    "\n",
    "# Impute Numeric Features with the mean value\n",
    "\n",
    "# One Hot Encode Categorical Features\n",
    "\n",
    "# Robust Scaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "rs = RobustScaler()\n",
    "df_clean[[\"age\", \"height\", \"weight\", \"ap_hi\", \"ap_lo\"]] = rs.fit_transform(df_clean[[\"age\", \"height\", \"weight\", \"ap_hi\", \"ap_lo\"]])\n",
    "\n",
    "\n",
    "X_cols = ['age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "y = df_clean['cardio']\n",
    "X = df_clean[X_cols]\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "clf_logreg = LogisticRegression(random_state=1, penalty='l2', C=0.1)\n",
    "\n",
    "\n",
    "acc = cross_val_score(clf_logreg, X, y=y, cv=cv)\n",
    "\n",
    "print (\"Average accuracy = \", acc.mean()*100, \"+-\", acc.std()*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work\n",
    "\n",
    "\n",
    "_You have free reign to provide additional analyses or combine analyses._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = ['age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "y = df_clean['cardio']\n",
    "\n",
    "X = df_clean[X_cols]\n",
    "\n",
    "clf_logreg = LogisticRegression(random_state=1)\n",
    "\n",
    "pipe_logreg = Pipeline([['clf', clf_logreg]])\n",
    "\n",
    "model_params = {\n",
    "    \"logisticregression\": {\n",
    "        \"model\": pipe_logreg,\n",
    "        \"params\": {\n",
    "            \"clf__C\": [.01, .1, 1, 5, 10, 25, 50],\n",
    "            \"clf__penalty\": [\"l1\", \"l2\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    start = time.time()\n",
    "    clf = GridSearchCV(estimator = mp[\"model\"], param_grid=mp[\"params\"], cv=10, scoring=\"roc_auc\", n_jobs=-1)\n",
    "    # clf = RandomizedSearchCV(estimator = mp[\"model\"], param_distributions=mp[\"params\"], cv=10, scoring=\"roc_auc\", n_jobs=-1)\n",
    "    clf.fit(X, y)\n",
    "    elapsed_time = (time.time() - start)\n",
    "\n",
    "    scores.append({\"Model\": model_name,\n",
    "    \"Best ROC AUC\": clf.best_score_, # Mean cross-validated score of the best_estimator\n",
    "    \"Best Params\": clf.best_params_,\n",
    "    \"results\": clf.cv_results_,\n",
    "    \"Cross Validation Time\": elapsed_time,\n",
    "    \"Best Estimator\": clf.best_estimator_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10 Fold Cross Validation Scores (Smoker):\n\nModel :  logisticregression\nBest ROC AUC :  0.7845476665556456\nBest Params :  {'clf__C': 0.01, 'clf__penalty': 'l2'}\nMean Fit Time:  0.2695335405213492\nMean Score Time:  0.0033628736223493307\nCross Validation Time :  12.064048290252686\nPrediction Accuracy :  0.7214616439922259\n"
    }
   ],
   "source": [
    "print('10 Fold Cross Validation Scores (Smoker):')\n",
    "\n",
    "for model in scores:\n",
    "    print()\n",
    "    for key, value in model.items():\n",
    "        if key == 'Best Estimator':\n",
    "            print(\"Prediction Accuracy\",': ',value.score(X, y))\n",
    "        elif key == 'results':\n",
    "            print('Mean Fit Time: ', value['mean_fit_time'].mean())\n",
    "            print('Mean Score Time: ', value['mean_score_time'].mean())\n",
    "        else:\n",
    "            print(key,': ',value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('ML7331': conda)",
   "language": "python",
   "name": "python_defaultSpec_1596379229881"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}